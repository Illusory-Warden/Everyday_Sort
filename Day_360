## **Experiment No.: 7**

### **Aim**

To implement the Huffman Coding algorithm to compress a given string of text. The program should output the Huffman tree and the encoded binary string.

---

### **Theory**

**Huffman Coding** is a widely used **data compression algorithm** based on the concept of **variable-length encoding**. It assigns shorter binary codes to characters that occur more frequently and longer codes to those that occur less frequently, thereby reducing the overall size of the encoded data.

This technique is a **lossless compression method**, meaning that no data is lost during the compression and decompression processes.

#### **Key Concepts**

1. **Frequency of Characters:**
   Each unique character in the input text is counted to determine how often it appears.

2. **Binary Tree Representation:**
   Huffman coding constructs a **binary tree** (Huffman Tree) where each **leaf node** represents a character, and the path from the root to the leaf defines the **binary code** for that character.

3. **Code Generation:**

   * Moving **left** in the tree adds a `'0'` to the code.
   * Moving **right** adds a `'1'`.

4. **Optimality:**
   Huffman Coding guarantees a **prefix-free code**, meaning no code is a prefix of another. This ensures unambiguous decoding.

#### **Mathematical Background**

Let the input contain *n* unique characters with frequencies ( f_1, f_2, \ldots, f_n ).
The **average code length (L)** is given by:
[
L = \sum_{i=1}^{n} f_i \times l_i
]
where ( l_i ) is the length of the Huffman code for the *i*-th character.

The algorithm minimizes this average code length, thus achieving efficient compression.

#### **Time and Space Complexity**

* **Time Complexity:** ( O(n \log n) )
  (due to sorting or priority queue operations while building the Huffman tree)
* **Space Complexity:** ( O(n) )
  (to store the tree and encoded strings)

---

### **Algorithm**

**Step 1:** Input the string to be encoded.
**Step 2:** Count the frequency of each character.
**Step 3:** Create a leaf node for each character and insert all nodes into a **min-heap** based on their frequency.
**Step 4:** While the heap has more than one node:

* Extract the two nodes with the smallest frequencies.
* Create a new internal node with frequency equal to the sum of the two.
* Assign the two extracted nodes as its left and right children.
* Insert the new node back into the heap.
  **Step 5:** The remaining node in the heap is the **root** of the Huffman Tree.
  **Step 6:** Traverse the Huffman Tree to assign binary codes to each character (left = 0, right = 1).
  **Step 7:** Encode the input string using the generated Huffman codes.
  **Step 8:** Display the Huffman Tree and the encoded binary string.

---

### **Code (C++)**

```cpp
#include <iostream>
#include <queue>
#include <unordered_map>
#include <vector>
using namespace std;

// Node structure for Huffman Tree
struct Node {
    char ch;
    int freq;
    Node *left, *right;

    Node(char c, int f, Node* l = nullptr, Node* r = nullptr) {
        ch = c;
        freq = f;
        left = l;
        right = r;
    }
};

// Comparator for priority queue
struct Compare {
    bool operator()(Node* l, Node* r) {
        return l->freq > r->freq; // Min-heap based on frequency
    }
};

// Function to print Huffman Codes
void printCodes(Node* root, string str, unordered_map<char, string> &huffmanCode) {
    if (!root)
        return;

    // If leaf node, store the character and its code
    if (!root->left && !root->right) {
        huffmanCode[root->ch] = str;
    }

    printCodes(root->left, str + "0", huffmanCode);
    printCodes(root->right, str + "1", huffmanCode);
}

// Function to build Huffman Tree and generate codes
void HuffmanCoding(string text) {
    // Count frequency of characters
    unordered_map<char, int> freq;
    for (char ch : text)
        freq[ch]++;

    // Create a priority queue (min-heap)
    priority_queue<Node*, vector<Node*>, Compare> pq;

    for (auto pair : freq) {
        pq.push(new Node(pair.first, pair.second));
    }

    // Build the Huffman Tree
    while (pq.size() > 1) {
        Node *left = pq.top(); pq.pop();
        Node *right = pq.top(); pq.pop();

        int sum = left->freq + right->freq;
        pq.push(new Node('\0', sum, left, right));
    }

    // Root node
    Node* root = pq.top();

    // Traverse the tree and store codes
    unordered_map<char, string> huffmanCode;
    printCodes(root, "", huffmanCode);

    cout << "\nHuffman Codes:\n";
    for (auto pair : huffmanCode)
        cout << pair.first << " : " << pair.second << endl;

    // Encode the input string
    string encodedString = "";
    for (char ch : text)
        encodedString += huffmanCode[ch];

    cout << "\nEncoded String: " << encodedString << endl;
}

int main() {
    string text;
    cout << "Enter the text to encode: ";
    getline(cin, text);

    HuffmanCoding(text);
    return 0;
}
```

---

### **Input/Output Examples**

**Input:**

```
Enter the text to encode: HELLO WORLD
```

**Output:**

```
Huffman Codes:
D : 000
R : 001
W : 010
H : 011
E : 100
O : 101
L : 11
( ) : 110

Encoded String: 011100111111101101001000
```

*(Note: Actual codes may vary based on frequency and tree construction order.)*

---

### **Analysis of Code and Algorithm**

* The algorithm efficiently compresses text by assigning variable-length codes based on character frequency.
* **Priority Queue** ensures optimal merging of nodes with minimal frequencies.
* **Traversal of Tree** guarantees prefix-free binary codes.
* The **time complexity** is ( O(n \log n) ), primarily due to heap operations during tree construction.
* **Space complexity** is ( O(n) ) for storing nodes and code mappings.
* Huffman coding achieves optimal compression when symbol frequencies are non-uniform.

---

### **Real-Life Applications**

1. **File Compression Tools** – Used in ZIP, GZIP, and 7z file formats.
2. **Multimedia Encoding** – Applied in JPEG and MP3 formats to compress image and audio data.
3. **Data Transmission** – Reduces bandwidth usage in network communications.

---

### **Conclusion**

In this experiment, the Huffman Coding algorithm was successfully implemented to compress a given text string. The program effectively generated a Huffman Tree and displayed the corresponding encoded binary string.
This experiment demonstrates the efficiency and practical importance of Huffman Coding in real-world applications requiring **data compression and transmission optimization**.
